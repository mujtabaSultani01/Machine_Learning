{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1d7307",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "**Cross validation** is a technique used to evaluate the performance of a predictive model and assess its accuracy. It works by dividing the dataset into training and testing sets, then using the training set to build the model and the testing set to evaluate the modelâ€™s performance. This process is repeated multiple times with different combinations of training and testing sets, and the results are averaged to get an overall accuracy score. Cross validation helps ensure that the model is not overfitting or underfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5bdf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries...\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9617bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the dataset into train and test samples:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ea2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Logisctic Regression Classifire:\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a38e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861111111111112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Support Vector Machine Classifier: \n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278eae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Random Forest Classifier:\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81655b73",
   "metadata": {},
   "source": [
    "* So this is the quick result of three algorithms. As we see we split the data: 80% is using for training and 20% is using for testing. But this splitting is not uniform, if we execute it again and again it will change the samples and finally will brings changes in the models performance. So this is the key problem with train_test_split method that you can't run the model once and judge whether my model is performing better then other models. You must run it multiple times.\n",
    "* Now let's in coming part check K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034fef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call K-Fold:\n",
    "# n_splits specify how many fold do you want?\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df9b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# Now the folds are created. The way we use this K-fold on the datasets is:\n",
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c9080",
   "metadata": {},
   "source": [
    "* So as we see the sample dataset[1-9] is splited into three folds. in First iteration it used first fold [0 1 2] for testing and remaining [3 4 5 6 7 8 ] for training. in the second iteration it used [3 4 5] for testing and [0 1 2 6 7 8] for training. and similar in 3rd iteration. \n",
    "* So now we use K-fold for our Digits example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9929b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify the things, we create a generic method which takes a model, X_train, X_test, y_train and y_test as input.\n",
    "# And then train the corresponding model:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
