{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0432fef",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "**Ensemble learning** is a machine learning technique that combines multiple models to create a more powerful and accurate model. It works by training multiple models using different algorithms or different sets of input data, then combining the predictions of these models to create a consensus prediction. This approach can be used to improve the accuracy of a model and reduce the risk of overfitting. Ensemble learning is commonly used in a variety of applications such as image recognition, fraud detection and medical diagnosis.\n",
    "\n",
    "**Bagging and boosting** are two popular techniques used in ensemble learning. Bagging involves training multiple models on different subsets of the data and combining their predictions to create a consensus prediction. Boosting involves training multiple models sequentially, where each model is trained to correct the mistakes of the previous model. Both techniques can be used to improve the accuracy of a model by reducing the variance or bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a82a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So first let's import the dataset. Here we use Diabetes dataset:\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f21ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21296ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do some explorations. First we need to check the null values:\n",
    "df.isnull().sum()\n",
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efe86f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second is to describe the dataset to see the basic statistics for each column:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b111ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the dataset is looking normal, there is no need for outlier removal or other preprocessing steps. The next thing we \n",
    "# want to define is the imbalance in the dataset:\n",
    "df.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1900bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we see that there are 500 samples which says no diabetes and 268 samples which says there are diabetes. So if we look \n",
    "# at the ratio:\n",
    "268/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73743037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that there is no big imbalance, it's almost 1/2 ratio (it's not 1/100 or 1/1000 ratio), so we go a head and create \n",
    "# 'x' and 'y':\n",
    "x = df.drop([\"Outcome\"], axis = \"columns\")\n",
    "y = df.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce593520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075,  0.90726993, -0.69289057,\n",
       "         0.20401277,  0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575,  0.53090156, -0.69289057,\n",
       "        -0.68442195, -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, -1.28821221, -0.69289057,\n",
       "        -1.10325546,  0.60439732, -0.10558415],\n",
       "       [-0.84488505, -0.99820778, -0.16054575,  0.15453319,  0.12330164,\n",
       "        -0.49404308, -0.92076261, -1.04154944],\n",
       "       [-1.14185152,  0.5040552 , -1.50468724,  0.90726993,  0.76583594,\n",
       "         1.4097456 ,  5.4849091 , -0.0204964 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to do scalling, because the values are in different range. Here we use standard scalling, you can use \n",
    "# Max - Min scalling:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_scaled = scl.fit_transform(x)\n",
    "x_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86fc0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we call train_test_split method to split the dataset:\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, stratify = y, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3210e2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train samples are:\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc75f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test samples are:\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "836927ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69480519, 0.66233766, 0.7012987 , 0.78431373, 0.7254902 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here for model training we use Decision Tree Classifier, because it's imbalance classifier, it can overfit and it will\n",
    "# generage high variance model. Additionaly we use cross validation scores right here.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), x, y, cv = 5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b56d3e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136490960020372"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the average scores:\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ebc365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517361111111112"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's use bagging classifier:\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Here some of the parameters are assigned, you can check all the parameters, and see which give you the better result.\n",
    "bag_model = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(x_train, y_train)\n",
    "bag_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b406980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864583333333334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to check the regular scores:\n",
    "bag_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aee948",
   "metadata": {},
   "source": [
    "* So we see the improvment from standalone classifier which has 71% accuracy to 78% accuracty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94268ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75324675, 0.72727273, 0.74675325, 0.82352941, 0.73856209])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to use cross validation with the bagging:\n",
    "bag_model = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "scores = cross_val_score(bag_model, x, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24857d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578728461081402"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the average scores:\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63790fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7656990068754774"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier also use bagging, it will not sample your data based on rows but it will sample your features (columns) as well.\n",
    "# To see the performance of Random Forest classifier, let's use it:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators=50), x, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad61747",
   "metadata": {},
   "source": [
    "* So RF is performing a bit better than DT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab07744",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Download heart disease dataset heart.csv in Exercise folder and do following, (credits of dataset: https://www.kaggle.com/fedesoriano/heart-failure-prediction)\n",
    "\n",
    "   1. Load heart disease dataset in pandas dataframe\n",
    "   2. Remove outliers using Z score. Usual guideline is to remove anything that has Z score > 3 formula or Z score < -3\n",
    "   3. Convert text columns to numbers using label encoding and one hot encoding\n",
    "   4. Apply scaling\n",
    "   5. Build a classification model using support vector machine. Use standalone model as well as Bagging model and check if you see any difference in the performance.\n",
    "   6. Now use decision tree classifier. Use standalone model as well as Bagging and check if you notice any difference in performance\n",
    "   7. Comparing performance of svm and decision tree classifier figure out where it makes most sense to use bagging and why. Use internet to figure out in what conditions bagging works the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb38b167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first import the dataset:\n",
    "dfe = pd.read_csv(\"heart.csv\")\n",
    "dfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8330e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Sex               0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So first let's check the Null values:\n",
    "dfe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "581839d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.510893</td>\n",
       "      <td>132.396514</td>\n",
       "      <td>198.799564</td>\n",
       "      <td>0.233115</td>\n",
       "      <td>136.809368</td>\n",
       "      <td>0.887364</td>\n",
       "      <td>0.553377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.432617</td>\n",
       "      <td>18.514154</td>\n",
       "      <td>109.384145</td>\n",
       "      <td>0.423046</td>\n",
       "      <td>25.460334</td>\n",
       "      <td>1.066570</td>\n",
       "      <td>0.497414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>173.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
       "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
       "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
       "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
       "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
       "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
       "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
       "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
       "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
       "\n",
       "          Oldpeak  HeartDisease  \n",
       "count  918.000000    918.000000  \n",
       "mean     0.887364      0.553377  \n",
       "std      1.066570      0.497414  \n",
       "min     -2.600000      0.000000  \n",
       "25%      0.000000      0.000000  \n",
       "50%      0.600000      1.000000  \n",
       "75%      1.500000      1.000000  \n",
       "max      6.200000      1.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no null values. Next to check statistics of the dataset:\n",
    "dfe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff478095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    508\n",
       "0    410\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see imbalance in the dataset:\n",
    "dfe.HeartDisease.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "624e0437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070866141732284"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the ratio:\n",
    "410/508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27739655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ExerciseAngina_Y</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  \\\n",
       "0   40        140          289          0    172      0.0             0   \n",
       "1   49        160          180          0    156      1.0             1   \n",
       "2   37        130          283          0     98      0.0             0   \n",
       "3   48        138          214          0    108      1.5             1   \n",
       "4   54        150          195          0    122      0.0             0   \n",
       "\n",
       "   Sex_M  ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  \\\n",
       "0      1                  1                  0                 0   \n",
       "1      0                  0                  1                 0   \n",
       "2      1                  1                  0                 0   \n",
       "3      0                  0                  0                 0   \n",
       "4      1                  0                  1                 0   \n",
       "\n",
       "   RestingECG_Normal  RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  \\\n",
       "0                  1              0                 0              0   \n",
       "1                  1              0                 0              1   \n",
       "2                  0              1                 0              0   \n",
       "3                  1              0                 1              1   \n",
       "4                  1              0                 0              0   \n",
       "\n",
       "   ST_Slope_Up  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to convert the string columns to numbers using get_dummies method:\n",
    "new_dfe = pd.get_dummies(dfe, drop_first=True)\n",
    "new_dfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8ec9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create 'x' and 'y':\n",
    "X = new_dfe.drop([\"HeartDisease\"], axis = \"columns\")\n",
    "Y = new_dfe.HeartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdca3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4331398 ,  0.41090889,  0.82507026, -0.55134134,  1.38292822,\n",
       "        -0.83243239,  0.51595242,  2.07517671, -0.53283777, -0.22967867,\n",
       "         0.81427482, -0.49044933, -0.8235563 , -1.00218103,  1.15067399],\n",
       "       [-0.47848359,  1.49175234, -0.17196105, -0.55134134,  0.75415714,\n",
       "         0.10566353, -1.93816322, -0.48188667,  1.87674385, -0.22967867,\n",
       "         0.81427482, -0.49044933, -0.8235563 ,  0.99782372, -0.86905588],\n",
       "       [-1.75135854, -0.12951283,  0.7701878 , -0.55134134, -1.52513802,\n",
       "        -0.83243239,  0.51595242,  2.07517671, -0.53283777, -0.22967867,\n",
       "        -1.22808661,  2.03894663, -0.8235563 , -1.00218103,  1.15067399],\n",
       "       [-0.5845565 ,  0.30282455,  0.13903954, -0.55134134, -1.13215609,\n",
       "         0.57471149, -1.93816322, -0.48188667, -0.53283777, -0.22967867,\n",
       "         0.81427482, -0.49044933,  1.21424608,  0.99782372, -0.86905588],\n",
       "       [ 0.05188098,  0.95133062, -0.0347549 , -0.55134134, -0.5819814 ,\n",
       "        -0.83243239,  0.51595242, -0.48188667,  1.87674385, -0.22967867,\n",
       "         0.81427482, -0.49044933, -0.8235563 , -1.00218103,  1.15067399]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next step is scall the columns using Standard Scaller:\n",
    "scle = StandardScaler()\n",
    "xe_scaled = scle.fit_transform(X)\n",
    "xe_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e7401cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we call train_test_split method to split the dataset:\n",
    "xe_train, xe_test, ye_train, ye_test = train_test_split(xe_scaled, Y, stratify = Y, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "631cee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61413043, 0.79347826, 0.69021739, 0.71584699, 0.61748634])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's create SVM as stand alone model:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_e = cross_val_score(SVC(), X, Y, cv = 5)\n",
    "scores_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "989e53b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686231884057971"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To average the result:\n",
    "scores_e.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc357527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8837209302325582"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's create bagging of SVM:\n",
    "bag_model_e = BaggingClassifier(\n",
    "    base_estimator=SVC(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model_e.fit(xe_train, ye_train)\n",
    "bag_model_e.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5eca0345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478260869565217"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the actual scores:\n",
    "bag_model_e.score(xe_test, ye_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51aec5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61956522, 0.79347826, 0.69565217, 0.71584699, 0.61748634])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's use cross validation scores with bagging:\n",
    "bag_model_ec = BaggingClassifier(\n",
    "    base_estimator=SVC(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "scores_ec = cross_val_score(bag_model_ec, X, Y, cv=5)\n",
    "scores_ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6cea0bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884057971014493"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ec.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2e79b",
   "metadata": {},
   "source": [
    "As you can see above, using bagging in case of SVM doesn't make much difference in terms of model accuracy. Bagging is effective when we have high variance and instable model such as decision tree. Let's explore how bagging changes the performance for a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f371f0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.72282609, 0.78804348, 0.67759563, 0.69398907])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's use Decision Tree classifier as standalone:\n",
    "scores_dt = cross_val_score(DecisionTreeClassifier(), X, Y, cv = 5)\n",
    "scores_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f6c5835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7264908529341886"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52583062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8531976744186046"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's use cross validation scores with bagging:\n",
    "bag_model_dt = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model_dt.fit(xe_train, ye_train)\n",
    "bag_model_dt.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bd669b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304347826086956"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the actual scores:\n",
    "bag_model_dt.score(xe_test, ye_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "501da5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8423913 , 0.83152174, 0.82065217, 0.78688525, 0.72677596])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the scores with cross validation:\n",
    "bag_model_dt = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "scores_dt = cross_val_score(bag_model_dt, X, Y, cv=5)\n",
    "scores_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "288da4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016452839154192"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the average:\n",
    "scores_dt.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0717332",
   "metadata": {},
   "source": [
    "* We clearly see the different in both cases (without Cross Vali Sc and with Cross Vali Sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e88eb6",
   "metadata": {},
   "source": [
    "#### That's were all about Ensemble (bagging) ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
