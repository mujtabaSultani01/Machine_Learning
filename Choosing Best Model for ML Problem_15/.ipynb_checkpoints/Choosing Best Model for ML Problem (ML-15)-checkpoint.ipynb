{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e58b8b",
   "metadata": {},
   "source": [
    "## Coosing Best Model for ML Problem\n",
    "**Choosing the best model for your machine learning problem** depends on several factors, including the type of problem you are trying to solve, the complexity of the data, and the computing resources available. It is important to understand the strengths and weaknesses of each model and determine which one best fits the task. It is also important to consider the various hyperparameters of each model and determine which ones will produce the most accurate results. Finally, it is important to assess the performance of each model using a validation set or cross-validation.\n",
    "* Here we mostly discuss the model analysis, it means how to choose the train and test samples>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83521aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For assessing different Model for a given problem, let's start from a simple example right here. \n",
    "from sklearn import svm, datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a05acd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   flower  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's here import pandas, and create a dataFrame from sklearn Iris dataset:\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df['flower'] = iris.target\n",
    "df['flower'] = df['flower'].apply(lambda x: iris.target_names[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063f0b6",
   "metadata": {},
   "source": [
    "**We have try three different approaches for choosing train and test samples right here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3db17b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"> Approach 1: </h2> Using train_test_split method and manually tune parameters by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b0d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The traditional approach is using train_test_split method. Let's here call it again:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d38ed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we randomely choose the parameters (parameter tuning), so I don't know which one is the best? \n",
    "# The main issue with train_test_split method is that: based on train and test sample your model score will be different. When\n",
    "# you execute the [4] statement twice and trice, you will see that the score is changing. So we can't rely on this method because\n",
    "# our score is changing based on execution. \n",
    "# Let's try first SVM model:\n",
    "svm_model = svm.SVC(kernel='rbf', C = 30, gamma = 'auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf8073",
   "metadata": {},
   "source": [
    "* To avoid the score changing, we use K-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d64bab",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"> Approach 2: </h2> Using K-Fold Cross Validataion.\n",
    "       \n",
    "    * So here we use different Kernal prameter tuning for K-Fold validation technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f92f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call the K-Fold cross validation:\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78b08bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying cross validation on SVM using 'kernal = linear' and 'C = 10':\n",
    "cross_val_score(svm.SVC(kernel = 'linear', C = 10, gamma = 'auto'), iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94ec5a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying cross validation on SVM using 'Kernal = rbf' and 'C = 10':\n",
    "cross_val_score(svm.SVC(kernel = 'rbf', C = 10, gamma = 'auto'), iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4026d9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying cross validation on SVM using 'Kernal = rbf' and 'C = 20':\n",
    "cross_val_score(svm.SVC(kernel='rbf',C=20,gamma='auto'),iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e6a02",
   "metadata": {},
   "source": [
    "* So now from upper three different resulst we can take average and decide the best parameters (parameter tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49884e81",
   "metadata": {},
   "source": [
    "The main problem of this approach is that, you have so many parameters and till what you will be changing the parameters and taking the average to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58c86cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': 0.9800000000000001,\n",
       " 'rbf_10': 0.9800000000000001,\n",
       " 'rbf_20': 0.9666666666666668,\n",
       " 'linear_1': 0.9800000000000001,\n",
       " 'linear_10': 0.9733333333333334,\n",
       " 'linear_20': 0.9666666666666666}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So for cross fold validation we can use for loop which will help us to find the best parameters so quickly:\n",
    "import numpy as np\n",
    "kernels = ['rbf', 'linear']\n",
    "C = [1, 10, 20]\n",
    "avg_scores = {}\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(svm.SVC(kernel = kval, C = cval, gamma = 'auto'), iris.data, iris.target, cv = 5)\n",
    "        avg_scores[kval + '_' + str(cval)] = np.average(cv_scores)\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9859b0",
   "metadata": {},
   "source": [
    "* From above results we can say that rbf with C=1 or 10 or linear with C=1 will give best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8418a03",
   "metadata": {},
   "source": [
    "- The above approach (for loop) again has some issues like if I have 4 parameters instead of two (kernels & C), then I have to run 4 loops, So it will be much computation and iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dc3f1",
   "metadata": {},
   "source": [
    "**So to avoid all these issues, Sklearn provide an API called GridSearchCV which will do the exact same thing (loop ...[26]).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3cda1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the first thing is importing the GridSearchCV:\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aeaa594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00200138, 0.00099974, 0.00080228, 0.00097823, 0.00120091,\n",
       "        0.00040059]),\n",
       " 'std_fit_time': array([0.00063333, 0.00062683, 0.00040117, 0.00059905, 0.00040209,\n",
       "        0.00049062]),\n",
       " 'mean_score_time': array([0.00160179, 0.00080171, 0.00060096, 0.00039997, 0.00019994,\n",
       "        0.00060415]),\n",
       " 'std_score_time': array([0.00049098, 0.00075041, 0.00049068, 0.00048986, 0.00039988,\n",
       "        0.00049334]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 0.96666667, 1.        , 0.96666667,\n",
       "        1.        ]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.9       , 0.9       ,\n",
       "        0.9       ]),\n",
       " 'split3_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "        0.93333333]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.97333333, 0.96666667,\n",
       "        0.96666667]),\n",
       " 'std_test_score': array([0.01632993, 0.01632993, 0.01632993, 0.03887301, 0.03651484,\n",
       "        0.0421637 ]),\n",
       " 'rank_test_score': array([1, 1, 1, 4, 5, 6])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we define the classifier, in the classifier the first parameter is our model, the second parameter is you grid:\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1,10,20],\n",
    "    'kernel': ['rbf','linear']\n",
    "}, cv=5, return_train_score=False)\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a1c33",
   "metadata": {},
   "source": [
    "* The result oup putted here will be difficult to read, so we can import it into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e430688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.036515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002001      0.000633         0.001602        0.000491       1   \n",
       "1       0.001000      0.000627         0.000802        0.000750       1   \n",
       "2       0.000802      0.000401         0.000601        0.000491      10   \n",
       "3       0.000978      0.000599         0.000400        0.000490      10   \n",
       "4       0.001201      0.000402         0.000200        0.000400      20   \n",
       "5       0.000401      0.000491         0.000604        0.000493      20   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0          rbf      {'C': 1, 'kernel': 'rbf'}           0.966667   \n",
       "1       linear   {'C': 1, 'kernel': 'linear'}           0.966667   \n",
       "2          rbf     {'C': 10, 'kernel': 'rbf'}           0.966667   \n",
       "3       linear  {'C': 10, 'kernel': 'linear'}           1.000000   \n",
       "4          rbf     {'C': 20, 'kernel': 'rbf'}           0.966667   \n",
       "5       linear  {'C': 20, 'kernel': 'linear'}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                1.0           0.966667           0.966667                1.0   \n",
       "1                1.0           0.966667           0.966667                1.0   \n",
       "2                1.0           0.966667           0.966667                1.0   \n",
       "3                1.0           0.900000           0.966667                1.0   \n",
       "4                1.0           0.900000           0.966667                1.0   \n",
       "5                1.0           0.900000           0.933333                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.980000        0.016330                1  \n",
       "1         0.980000        0.016330                1  \n",
       "2         0.980000        0.016330                1  \n",
       "3         0.973333        0.038873                4  \n",
       "4         0.966667        0.036515                5  \n",
       "5         0.966667        0.042164                6  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the result into the DataFrame:\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7b9f1",
   "metadata": {},
   "source": [
    "* So the upper table is a nice visualization, we have C parameters, kernels parameter and scores for each splits (We run 5-fold validation so we see split0 to split4). And we also have rank_test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "854d0e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0       1          rbf         0.980000\n",
       "1       1       linear         0.980000\n",
       "2      10          rbf         0.980000\n",
       "3      10       linear         0.973333\n",
       "4      20          rbf         0.966667\n",
       "5      20       linear         0.966667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some parameters in the above DataFrame might be not useful so we create a sub DataFrame for quick result:\n",
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff53731",
   "metadata": {},
   "source": [
    "* So here we clear see the parameters against their scores. So we can get which parameters can produce a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f7e721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_select_best_index',\n",
       " '_validate_data',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's dir() the classifier to show which other properties this object has:\n",
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d135085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the 'best_score_' property:\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d30f0677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see best parameters:\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef8675",
   "metadata": {},
   "source": [
    "* One issue with the GridSearchCV is computation cost. Now our dataset is very limited but if you have milion of data points for you dataset, so it will takes mcuh time.\n",
    "* GridSearchCV do permutation and combination for every value in each of the parameters [C (...) & Kernals (...)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268115d5",
   "metadata": {},
   "source": [
    "* To tackle with this much pumutation and combination, sklearn library comes with another class called RandomizedSearchCV. This CV not try to do every single permutation and combination but try to do it randomly. You can choose for CV, what those iteration could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "681265b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      10       linear         0.973333\n",
       "1      20       linear         0.966667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how RadomizedSearchCV works?\n",
    "# The API is looking most similar with GridSearchCV.\n",
    "# The interesting parameter is here 'n_iter = 2'. here we have two iterations, but if you see previously [31] we had six iterations.\n",
    "# So after we call fit method and dowload the result into the datafram.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "        'C': [1,10,20],\n",
    "        'kernel': ['rbf','linear']\n",
    "    }, \n",
    "    cv=5, \n",
    "    return_train_score=False, \n",
    "    n_iter=2\n",
    ")\n",
    "rs.fit(iris.data, iris.target)\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d23d7",
   "metadata": {},
   "source": [
    "* We see that it perform two iterations at a time. Every time when you run it again it changes the values and parameters.\n",
    "* This work will in the practical life."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d8cf9",
   "metadata": {},
   "source": [
    "### So till now we were talking about Hyper Parameter Tuning. Now let's talk how to choose a best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "582ea737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sklearn Iris dataset let's try the three algorithms 1) Random Forest Classifier 2) Logistic Regression 3) SVM.\n",
    "# We want to figure out which one give me the best performance?\n",
    "# Here the parameters are defined by JSon Object using simple Python Dictionary.\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "568b4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the simple 'for loop' is define here, this 'for loop' is just going on the dictionary and for each of the values it \n",
    "# will used GridSearchCV. So we see the first parameter of GridSearchCV is your Model, and the second one is the parameters.\n",
    "# So then the training is run and the scores append to scores list. When we run it the scors list has all those values.\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ea13ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                best_params\n",
       "0                  svm    0.980000  {'C': 1, 'kernel': 'rbf'}\n",
       "1        random_forest    0.953333        {'n_estimators': 5}\n",
       "2  logistic_regression    0.966667                   {'C': 5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we convert those result into pandas DataFrame: \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a72b08",
   "metadata": {},
   "source": [
    "* Based on above, we can conclude that SVM with C=1 and kernel='rbf' is the best model for solving my problem of iris flower classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd3788",
   "metadata": {},
   "source": [
    "* <h3 style = \"color:green\">So from this DataFrame we can conclude which classifier with which parameters has better performance for sklearn Iris dataset?</h3>\n",
    "* Here we had three classifier, but we can have 10 or 20 classifier and dicide which one do better for a specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d60c7",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "For digits dataset in sklearn.dataset, please try following classifiers and find out the one that gives best performance. Also find the optimal parameters for that classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bf096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147a0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first import the dataset:\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef45b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's again see what we have in the dataset:\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75269e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the different parameters:\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c8ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create the models parameters:\n",
    "model_parameters = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1, 5, 10, 15, 20],\n",
    "            'kernel': ['rbf','linear', 'poly', 'sigmoid'],\n",
    "            'degree': [1, 2, 3, 4, 5, 6]     \n",
    "        }  \n",
    "    },\n",
    "    'naive_bayes_gaussian': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'naive_bayes_multinomial': {\n",
    "        'model': MultinomialNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini','entropy'],\n",
    "            'splitter' : [\"best\", \"random\"],\n",
    "            'max_features' : [\"auto\", \"sqrt\", \"log2\"]\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,3, 5, 8, 12, 15],\n",
    "            'criterion' : [\"gini\", \"entropy\"]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10],\n",
    "            'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'multi_class' : ['auto', 'ovr', 'multinomial']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7828e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1519, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 483, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Habib\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.92767874 0.9221139         nan        nan 0.92878985 0.9221139\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.92044259 0.91822037        nan        nan 0.92044104 0.91822037\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91766171 0.91822346        nan        nan 0.91766326 0.91822346\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Call for the GridSearchCV and define the classifier:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_parameters.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(digits.data, digits.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45414017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.968842</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive_bayes_gaussian</td>\n",
       "      <td>0.806928</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive_bayes_multinomial</td>\n",
       "      <td>0.870350</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.755758</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.915446</td>\n",
       "      <td>{'criterion': 'entropy', 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.928790</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  best_score  \\\n",
       "0                      svm    0.968842   \n",
       "1     naive_bayes_gaussian    0.806928   \n",
       "2  naive_bayes_multinomial    0.870350   \n",
       "3            decision_tree    0.755758   \n",
       "4            random_forest    0.915446   \n",
       "5      logistic_regression    0.928790   \n",
       "\n",
       "                                         best_params  \n",
       "0            {'C': 1, 'degree': 3, 'kernel': 'poly'}  \n",
       "1                                                 {}  \n",
       "2                                                 {}  \n",
       "3  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
       "4       {'criterion': 'entropy', 'n_estimators': 15}  \n",
       "5    {'C': 1, 'multi_class': 'ovr', 'penalty': 'l1'}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call to pandas and print the result in a DataFrame:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3aae9",
   "metadata": {},
   "source": [
    "Thats were all about Prameter tuning and choosing the best model for your ML problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
